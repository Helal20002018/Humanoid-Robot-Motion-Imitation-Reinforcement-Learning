# Humanoid-Robot-Motion-Imitation-Reinforcement-Learning

üìå Project Overview

This project was developed on the Ubtech Yanshee humanoid robot.
The focus was to enable the robot to mirror human upper-body movements using external camera measurements and to explore reinforcement learning (RL) for extending motion capabilities.
 
 ![Untitled video - Made with Clipchamp](https://github.com/user-attachments/assets/a3b16236-ac78-49cc-bce1-8cd58e8fc022)




üîß My Contributions

Human Motion Tracking: Designed a script to capture body dimensions (shoulder‚Äìelbow and elbow‚Äìwrist) from an external camera.

Motion Imitation on Yanshee: Developed control scripts to drive the robot‚Äôs servos so that it mirrors my own arm and head movements in real time.

Head Movement Replication: Implemented real-time tracking for left‚Äìright head rotations.

Accuracy Optimization: Achieved high precision in servo control to ensure the robot closely follows human motions.

Reinforcement Learning: Applied RL techniques to enhance motion performance and explore new movement behaviors.

Application-Oriented Design: Designed the system for scenarios where humans should avoid direct exposure (e.g., hazardous tasks), allowing the robot to act as a substitute.

üõ†Ô∏è Tools & Technologies

Frameworks: ROS / ROS 2, OpenCV

Simulation & Learning: Reinforcement Learning (RL)

Hardware: Ubtech Yanshee humanoid robot, external camera

Methods: Motion Imitation, Human-to-Robot Mapping, Servo Control, Reinforcement Learning

üöÄ Outcome

Successfully achieved accurate real-time motion imitation from human to robot.

Enabled head and arm mirroring with precise servo synchronization.

Validated the system‚Äôs potential for remote task execution, where the robot substitutes for a human.

Explored reinforcement learning for extending movement capabilities beyond direct imitation.
